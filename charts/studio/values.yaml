# Default values for studio.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

############################
# THIS IS WORK IN PROGRESS #
############################

# -- (string) Override name of app
nameOverride: ""
# -- (string) Override the full qualified app name
fullnameOverride: ""

# -- imagePullSecret defines repository pull secrets
imagePullSecrets:
  []
  # - name: regcred

# -- repository specifies image repository for Studio
repository: "europe-west3-docker.pkg.dev/rasa-releases/studio/"
# -- tag specifies image tag for Studio
## Overrides the image tag whose default is the chart appVersion.
tag: "1.12.2"

config:
  # -- Defines the host name for all Studio ingress resources.
  # This value is used as an anchor (&dns_hostname) for referencing the host name across multiple places in the Helm chart.
  # WARNING: Do NOT delete or modify the anchor (&dns_hostname) as it is critical for the proper functioning of the chart.
  # If you need to update the host name, only change the value (INGRESS.HOST.NAME), keeping the anchor intact.
  ingressHost: &dns_hostname INGRESS.HOST.NAME

  # -- Define the ingress annotations to be used for ALL the ingress resources.
  # These annotations will be applied to all ingress resources created by this chart.
  # Example:
  #   kubernetes.io/ingress.class: nginx
  #   cert-manager.io/cluster-issuer: letsencrypt-prod
  ingressAnnotations: {}

  # -- Define if you will be using https or http with the ingressHost.
  # Valid values are "http" or "https". This setting affects how services communicate with each other.
  connectionType: "http"

  # -- The postgres database instance details for Studio to connect to.
  # This section configures the database connection parameters for Studio.
  database:
    # -- The database host name or IP address where PostgreSQL is running.
    # Example: "postgres.example.com" or "10.0.0.1"
    host: ""
    # -- The database port number for PostgreSQL.
    # Default PostgreSQL port is 5432
    port: "5432"
    # -- The database username for Studio to connect with.
    # This user should have appropriate permissions on the database.
    username: ""
    # -- The database password configuration.
    # This references a Kubernetes secret containing the database password.
    password:
      secretName: "studio-secrets"
      secretKey: "DATABASE_PASSWORD"
    # -- Set to true if you want to use SSL for database connection.
    # When enabled, Studio will attempt to establish an encrypted connection to the database.
    preferSSL: "true"
    # -- If true, the server will reject database connections which are not present in the list of supplied CAs.
    # This provides additional security by ensuring only trusted certificates are accepted.
    rejectUnauthorized: ""
    # -- The database name for Keycloak user management service.
    # This is used by Keycloak to store its user management data.
    keycloakDatabaseName: "keycloak"

  # -- config.keycloak defines the Keycloak configuration settings.
  # This section configures the authentication and authorization service.
  keycloak:
    # -- config.keycloak.url overrides the default service endpoint for Keycloak.
    # Format is `http(s)://<ingressHost>/auth`.
    # Required only if your cluster redirects internal HTTP traffic to HTTPS.
    url: ""
    # -- config.keycloak.adminUsername is the admin username for Keycloak.
    # This username is used to login to the Keycloak admin console.
    adminUsername: "kcadmin"
    # -- config.keycloak.adminPassword defines the admin password for Keycloak.
    # This password is used to login to the Keycloak admin console.
    # The password is stored in a Kubernetes secret.
    adminPassword:
      secretName: "studio-secrets"
      secretKey: "KEYCLOAK_ADMIN_PASSWORD"

  # -- Common pod scheduling configuration for all deployments.
  # These settings can be overridden by component-specific configurations.
  nodeSelector: {}
  # Example:
  # nodeSelector:
  #   kubernetes.io/os: linux
  #   node-role.kubernetes.io/worker: "true"

  # -- Pod affinity and anti-affinity rules for all deployments.
  # These settings can be overridden by component-specific configurations.
  affinity: {}
  # Example:
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: kubernetes.io/os
  #           operator: In
  #           values:
  #           - linux
  #   podAffinity:
  #     preferredDuringSchedulingIgnoredDuringExecution:
  #     - weight: 100
  #       podAffinityTerm:
  #         labelSelector:
  #           matchExpressions:
  #           - key: app
  #             operator: In
  #             values:
  #             - database
  #         topologyKey: kubernetes.io/hostname

  # -- Pod tolerations for all deployments.
  # These settings can be overridden by component-specific configurations.
  tolerations: []
  # Example:
  # tolerations:
  # - key: "key1"
  #   operator: "Equal"
  #   value: "value1"
  #   effect: "NoSchedule"
  # - key: "key2"
  #   operator: "Exists"
  #   effect: "NoExecute"

# Studio Backend component specific configuration
backend:
  # -- backend.replicaCount is the number of replicas for the Studio Backend deployment.
  # Increase this value for high availability and better load distribution.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#replicas
  replicaCount: 1

  # -- backend.image defines the container image settings for the backend service.
  # This section defines the container image settings for the backend service.
  # Ref: https://kubernetes.io/docs/concepts/containers/images/
  image:
    # -- backend.image.name is the name of the Studio Backend container image.
    # This should match the image name in your container registry.
    name: "studio-backend"
    # -- backend.image.pullPolicy is the container image pull policy.
    # Valid values: Always, IfNotPresent, Never
    # Always: Always pull the image
    # IfNotPresent: Only pull if not present locally
    # Never: Never pull the image
    # Ref: https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy
    pullPolicy: IfNotPresent

  # -- backend.environmentVariables defines the environment variables for the Studio Backend deployment.
  # These variables configure the runtime behavior of the backend service.
  # Each variable can be set either directly with a value or from a Kubernetes secret.
  # Example: Specify the string value for variables
  #   value: my-value
  # Example: Specify the value for variables sourced from a Secret.
  #   secret:
  #     name: my-secret
  #     key: my-secret-key
  # NOTE: Helm will return an error if environment variable does not have `value` or `secret` provided.
  # Ref: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  environmentVariables:
    # -- backend.environmentVariables.DATABASE_URL is the database connection URL for Studio Backend.
    # Format: postgresql://${database.username}:${database.password}@${database.host}:${database.port}/studio?schema=public
    # This should be stored in a Kubernetes secret for security.
    # Ref: https://kubernetes.io/docs/concepts/configuration/secret/
    DATABASE_URL:
      secret:
        name: "studio-secrets"
        key: "DATABASE_URL"
    # -- backend.environmentVariables.KEYCLOAK_REALM is the Keycloak realm name for Studio.
    # This defines the authentication realm where Studio users will be managed.
    KEYCLOAK_REALM:
      value: "rasa-studio"
    # -- backend.environmentVariables.KEYCLOAK_API_CLIENT_ID is the Keycloak client ID for API access.
    # This client is used by Studio Backend to authenticate with Keycloak.
    KEYCLOAK_API_CLIENT_ID:
      value: "admin-cli"
    # -- backend.environmentVariables.KEYCLOAK_API_USERNAME is the username for Studio Backend to communicate with Keycloak.
    # This account needs appropriate permissions in Keycloak to manage users.
    KEYCLOAK_API_USERNAME:
      value: "realmadmin"
    # -- backend.environmentVariables.KEYCLOAK_API_PASSWORD is the password for Studio Backend to communicate with Keycloak.
    # This should be stored in a Kubernetes secret for security.
    # Ref: https://kubernetes.io/docs/concepts/configuration/secret/
    KEYCLOAK_API_PASSWORD:
      secret:
        name: "studio-secrets"
        key: "KEYCLOAK_API_PASSWORD"
    # -- backend.environmentVariables.DELETE_CONVERSATIONS_OLDER_THAN_HOURS is the conversation data retention period in hours.
    # Conversations older than this value will be deleted by the cleanup cron job.
    # Leave empty to disable automatic conversation cleanup.
    # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/
    DELETE_CONVERSATIONS_OLDER_THAN_HOURS:
      value: ""
    # -- backend.environmentVariables.DELETE_CONVERSATIONS_CRON_EXPRESSION is the cron schedule for conversation cleanup job.
    # Format: "minute hour day-of-month month day-of-week"
    # Example: "0 * * * *" runs every hour
    # Default: Runs every hour at minute 0
    # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax
    DELETE_CONVERSATIONS_CRON_EXPRESSION:
      value: "0 * * * *"

  # -- backend.envFrom defines additional environment variables from ConfigMap or Secret.
  # These will be mounted as environment variables in the container.
  # Example:
  # - configMapRef:
  #     name: my-configmap
  # - secretRef:
  #     name: my-secret
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  envFrom:
    []

  # -- backend.additionalContainers defines additional containers to run alongside the main Studio Backend container.
  # These containers will be part of the same pod and share the pod's network namespace.
  # Example:
  # - name: sidecar
  #   image: busybox
  #   command: ["sh", "-c", "while true; do echo 'Sidecar running'; sleep 30; done"]
  # Ref: https://kubernetes.io/docs/concepts/workloads/pods/#how-pods-manage-multiple-containers
  additionalContainers: []

  # -- backend.serviceAccount defines the Kubernetes service account used by the backend pod.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccount:
    # -- backend.serviceAccount.create determines whether to create a new service account.
    create: false
    # -- backend.serviceAccount.annotations defines annotations to add to the service account.
    # Useful for cloud provider specific configurations.
    annotations: {}
    # -- backend.serviceAccount.name is the name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template.
    name: ""

  # -- backend.podAnnotations defines annotations to add to the backend pod.
  # Example:
  #   container.apparmor.security.beta.kubernetes.io/studio-backend: runtime/default
  # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations:
    {}

  # -- backend.podSecurityContext defines the security settings for the entire pod.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  podSecurityContext:
    # -- backend.podSecurityContext.enabled determines whether to enable the pod security context.
    enabled: true
    # -- backend.podSecurityContext.fsGroup is the group ID to run the container as.
    # fsGroup: 2000

  # -- backend.securityContext defines the security settings for the backend container.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  securityContext:
    # -- backend.securityContext.enabled determines whether to enable the security context.
    enabled: true
    # -- backend.securityContext.allowPrivilegeEscalation determines whether to allow privilege escalation.
    # Should be false for security best practices.
    allowPrivilegeEscalation: false
    # -- backend.securityContext.runAsNonRoot determines whether to run the container as a non-root user.
    # Should be true for security best practices.
    runAsNonRoot: true
    # -- backend.securityContext.capabilities defines the Linux capabilities configuration.
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-capabilities-for-a-container
    capabilities:
      # -- backend.securityContext.capabilities.drop defines capabilities to drop from the container.
      # ALL drops all capabilities for maximum security.
      drop:
        - ALL
      # -- backend.securityContext.capabilities.add defines capabilities to add to the container.
      # Uncomment and modify if specific capabilities are needed.
      # add: ['NET_BIND_SERVICE', 'NET_RAW']
    # -- backend.securityContext.privileged determines whether to run the container in privileged mode.
    # Should be false for security best practices.
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    # privileged: false
    # -- backend.securityContext.readOnlyRootFilesystem determines whether to mount the root filesystem as read-only.
    # Can be enabled for additional security.
    # readOnlyRootFilesystem: true
    # -- backend.securityContext.runAsUser is the user ID to run the container as.
    # runAsUser: 1000
    # -- backend.securityContext.seccompProfile defines the seccomp profile configuration.
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-seccomp-profile-for-a-container
    # seccompProfile:
    #   type: RuntimeDefault

  # -- backend.service defines how the backend service is exposed within the cluster.
  # Ref: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    # -- backend.service.type is the type of Kubernetes service.
    # Valid values: ClusterIP, NodePort, LoadBalancer, ExternalName
    # Ref: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    # -- backend.service.port is the port number for the service.
    port: 80
    # -- backend.service.targetPort is the target port in the container.
    # This should match the port your application listens on.
    targetPort: 4000

  # -- backend.livenessProbe defines the liveness probe configuration.
  # This determines if the container is alive and functioning.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  livenessProbe:
    # -- backend.livenessProbe.enabled determines whether to enable the liveness probe.
    enabled: true
    # -- backend.livenessProbe.httpGet defines the HTTP GET probe configuration.
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command
    httpGet:
      # -- backend.livenessProbe.httpGet.path is the path to check for liveness.
      path: /api/health
      # -- backend.livenessProbe.httpGet.port is the port to check for liveness.
      port: 4000
      # -- backend.livenessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- backend.livenessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 15
    # -- backend.livenessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- backend.livenessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- backend.livenessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- backend.livenessProbe.failureThreshold is the number of failures before the container is considered unhealthy.
    failureThreshold: 6

  # -- backend.readinessProbe defines the readiness probe configuration.
  # This determines if the container is ready to receive traffic.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  readinessProbe:
    # -- backend.readinessProbe.enabled determines whether to enable the readiness probe.
    enabled: true
    # -- backend.readinessProbe.httpGet defines the HTTP GET probe configuration.
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-readiness-probe
    httpGet:
      # -- backend.readinessProbe.httpGet.path is the path to check for readiness.
      path: /api/health
      # -- backend.readinessProbe.httpGet.port is the port to check for readiness.
      port: 4000
      # -- backend.readinessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- backend.readinessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 15
    # -- backend.readinessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- backend.readinessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- backend.readinessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- backend.readinessProbe.failureThreshold is the number of failures before the container is considered not ready.
    failureThreshold: 6

  # -- backend.migration defines the database migration job configuration.
  # This section controls the database schema migration process.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/job/
  migration:
    # -- backend.migration.enabled determines whether to enable the database migration job.
    # Set to false if you want to handle migrations manually.
    enabled: true
    # -- backend.migration.image defines the image configuration for the migration job.
    image:
      # -- backend.migration.image.name is the name of the migration container image.
      name: "studio-database-migration"
      # -- backend.migration.image.pullPolicy is the container image pull policy.
      pullPolicy: IfNotPresent

    # -- backend.migration.waitForIt determines whether to wait for the database to be ready before running migrations.
    waitForIt: false
    # -- backend.migration.waitFotItContainer defines the configuration for the wait-for-it container.
    waitFotItContainer:
      image: postgres:17.2

    # -- backend.migration.nodeSelector defines which nodes the migration job can run on.
    # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
    nodeSelector: {}

    # -- backend.migration.tolerations defines tolerations for the migration job.
    # This allows the job to run on nodes with matching taints.
    # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
    tolerations: []

    # -- backend.migration.affinity defines affinity rules for the migration job.
    # This controls where the job can be scheduled.
    # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
    affinity: {}

  # -- backend.ingress defines how the backend service is exposed externally.
  # Ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    # -- backend.ingress.enabled determines whether to create an ingress resource.
    enabled: true
    # -- backend.ingress.className is the ingress class name.
    # This should match your cluster's ingress controller.
    # Ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class
    className: ""
    # -- backend.ingress.labels defines labels to add to the ingress resource.
    # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    labels: {}
    # -- backend.ingress.additionalAnnotations defines additional annotations for the ingress resource.
    # Example:
    #   kubernetes.io/ingress.class: nginx
    #   cert-manager.io/cluster-issuer: letsencrypt-prod
    # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    additionalAnnotations: {}
    # -- backend.ingress.tls defines the TLS configuration for the ingress.
    # Example:
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local
    tls: []

  # -- backend.resources defines the resource limits and requests for Studio Backend.
  # This controls the compute resources allocated to the backend container.
  # Ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  resources:
    {}
    # Example configuration:
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # -- backend.autoscaling defines the Horizontal Pod Autoscaling configuration.
  # This enables automatic scaling of the backend deployment based on metrics.
  # Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  autoscaling:
    # -- backend.autoscaling.enabled determines whether to enable horizontal pod autoscaling.
    enabled: false
    # -- backend.autoscaling.minReplicas is the minimum number of replicas.
    minReplicas: 1
    # -- backend.autoscaling.maxReplicas is the maximum number of replicas.
    maxReplicas: 100
    # -- backend.autoscaling.targetCPUUtilizationPercentage is the target CPU utilization percentage.
    # The HPA will scale the deployment to maintain this CPU utilization.
    # Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details
    targetCPUUtilizationPercentage: 80
    # -- backend.autoscaling.targetMemoryUtilizationPercentage is the target memory utilization percentage.
    # Uncomment to enable memory-based scaling.
    # targetMemoryUtilizationPercentage: 80

  # -- backend.nodeSelector defines which nodes the backend pods can run on.
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
  nodeSelector: {}

  # -- backend.tolerations defines tolerations for the backend pods.
  # This allows the pods to run on nodes with matching taints.
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  tolerations: []

  # -- backend.affinity defines affinity rules for the backend pods.
  # This controls where the pods can be scheduled.
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

# Studio Web Client component specific configuration
webClient:
  # -- webClient.replicaCount is the number of replicas for the Web Client deployment.
  replicaCount: 1

  # -- webClient.image defines the container image settings for the web client service.
  image:
    # -- webClient.image.name is the name of the Web Client container image.
    name: "studio-web-client"
    # -- webClient.image.pullPolicy is the container image pull policy.
    pullPolicy: IfNotPresent

  # -- webClient.environmentVariables defines the environment variables for the Web Client deployment.
  # Example: Specify the string value for variables
  #   value: my-value
  # Example: Specify the value for variables sourced from a Secret.
  #   secret:
  #     name: my-secret
  #     key: my-secret-key
  # NOTE: Helm will return an error if environment variable does not have `value` or `secret` provided.
  environmentVariables:
    # -- webClient.environmentVariables.KEYCLOAK_REALM is the Keycloak realm name for Studio.
    KEYCLOAK_REALM: "rasa-studio"
    # -- webClient.environmentVariables.KEYCLOAK_CLIENT_ID is the Keycloak client ID for the web client.
    KEYCLOAK_CLIENT_ID: "rasa-studio-backend"

  # -- webClient.envFrom defines additional environment variables from ConfigMap or Secret.
  # Example:
  # - configMapRef:
  #     name: my-configmap
  # - secretRef:
  #     name: my-secret
  envFrom:
    []

  # -- webClient.additionalContainers defines additional containers to run alongside the main Web Client container.
  # Example:
  # - name: sidecar
  #   image: busybox
  #   command: ["sh", "-c", "while true; do echo 'Sidecar running'; sleep 30; done"]
  additionalContainers: []

  # -- webClient.serviceAccount defines the Kubernetes service account used by the web client pod.
  serviceAccount:
    # -- webClient.serviceAccount.create determines whether to create a new service account.
    create: false
    # -- webClient.serviceAccount.annotations defines annotations to add to the service account.
    annotations: {}
    # -- webClient.serviceAccount.name is the name of the service account to use.
    name: ""

  # -- webClient.podAnnotations defines annotations to add to the web client pod.
  # Example:
  #   container.apparmor.security.beta.kubernetes.io/studio-web-client: runtime/default
  podAnnotations:
    {}

  # -- webClient.podSecurityContext defines the security settings for the entire pod.
  podSecurityContext:
    # -- webClient.podSecurityContext.enabled determines whether to enable the pod security context.
    enabled: true
    # -- webClient.podSecurityContext.fsGroup is the group ID to run the container as.
    # fsGroup: 2000

  # -- webClient.securityContext defines the security settings for the web client container.
  securityContext:
    # -- webClient.securityContext.enabled determines whether to enable the security context.
    enabled: true
    # -- webClient.securityContext.allowPrivilegeEscalation determines whether to allow privilege escalation.
    allowPrivilegeEscalation: false
    # -- webClient.securityContext.runAsNonRoot determines whether to run the container as a non-root user.
    runAsNonRoot: true
    # -- webClient.securityContext.capabilities defines the Linux capabilities configuration.
    capabilities:
      # -- webClient.securityContext.capabilities.drop defines capabilities to drop from the container.
      drop:
        - ALL
      # -- webClient.securityContext.capabilities.add defines capabilities to add to the container.
      # add: ['NET_BIND_SERVICE', 'NET_RAW']
    # -- webClient.securityContext.privileged determines whether to run the container in privileged mode.
    # privileged: false
    # -- webClient.securityContext.readOnlyRootFilesystem determines whether to mount the root filesystem as read-only.
    # readOnlyRootFilesystem: true
    # -- webClient.securityContext.runAsUser is the user ID to run the container as.
    # runAsUser: 1000
    # -- webClient.securityContext.seccompProfile defines the seccomp profile configuration.
    # seccompProfile:
    #   type: RuntimeDefault

  # -- webClient.service defines how the web client service is exposed within the cluster.
  service:
    # -- webClient.service.type is the type of Kubernetes service.
    type: ClusterIP
    # -- webClient.service.port is the port number for the service.
    port: 80
    # -- webClient.service.targetPort is the target port in the container.
    targetPort: 8080

  # -- webClient.livenessProbe defines the liveness probe configuration.
  livenessProbe:
    # -- webClient.livenessProbe.enabled determines whether to enable the liveness probe.
    enabled: true
    # -- webClient.livenessProbe.httpGet defines the HTTP GET probe configuration.
    httpGet:
      # -- webClient.livenessProbe.httpGet.path is the path to check for liveness.
      path: /
      # -- webClient.livenessProbe.httpGet.port is the port to check for liveness.
      port: 8080
      # -- webClient.livenessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- webClient.livenessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 15
    # -- webClient.livenessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- webClient.livenessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- webClient.livenessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- webClient.livenessProbe.failureThreshold is the number of failures before the container is considered unhealthy.
    failureThreshold: 6

  # -- webClient.readinessProbe defines the readiness probe configuration.
  readinessProbe:
    # -- webClient.readinessProbe.enabled determines whether to enable the readiness probe.
    enabled: true
    # -- webClient.readinessProbe.httpGet defines the HTTP GET probe configuration.
    httpGet:
      # -- webClient.readinessProbe.httpGet.path is the path to check for readiness.
      path: /
      # -- webClient.readinessProbe.httpGet.port is the port to check for readiness.
      port: 8080
      # -- webClient.readinessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- webClient.readinessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 15
    # -- webClient.readinessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- webClient.readinessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- webClient.readinessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- webClient.readinessProbe.failureThreshold is the number of failures before the container is considered not ready.
    failureThreshold: 6

  # -- webClient.ingress defines how the web client service is exposed externally.
  ingress:
    # -- webClient.ingress.enabled determines whether to create an ingress resource.
    enabled: true
    # -- webClient.ingress.className is the ingress class name.
    className: ""
    # -- webClient.ingress.labels defines labels to add to the ingress resource.
    labels: {}
    # -- webClient.ingress.additionalAnnotations defines additional annotations for the ingress resource.
    additionalAnnotations: {}
    # -- webClient.ingress.tls defines the TLS configuration for the ingress.
    tls: []

  # -- webClient.resources defines the resource limits and requests for the web client.
  resources:
    {}
    # Example configuration:
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # -- webClient.nodeSelector defines which nodes the web client pods can run on.
  nodeSelector: {}

  # -- webClient.tolerations defines tolerations for the web client pods.
  tolerations: []

  # -- webClient.affinity defines affinity rules for the web client pods.
  affinity: {}

# Studio Event Ingestion component specific configuration
eventIngestion:
  # -- eventIngestion.enabled determines whether to deploy the event ingestion component.
  enabled: true
  # -- eventIngestion.replicaCount is the number of replicas for the Event Ingestion deployment.
  replicaCount: 1

  # -- eventIngestion.image defines the container image settings for the event ingestion service.
  image:
    # -- eventIngestion.image.name is the name of the Event Ingestion container image.
    name: "studio-event-ingestion"
    # -- eventIngestion.image.pullPolicy is the container image pull policy.
    pullPolicy: IfNotPresent

  # -- eventIngestion.environmentVariables defines the environment variables for the Event Ingestion deployment.
  # Example: Specify the string value for variables
  #   value: my-value
  # Example: Specify the value for variables sourced from a Secret.
  #   secret:
  #     name: my-secret
  #     key: my-secret-key
  # NOTE: Helm will return an error if environment variable does not have `value` or `secret` provided.
  environmentVariables:
    # -- eventIngestion.environmentVariables.DATABASE_URL is the database connection URL for Event Ingestion.
    # Format: postgresql://${DB_USER}:${DB_PASS}@${DB_HOST}:${DB_PORT}/${DB_NAME}?schema=public
    DATABASE_URL:
      secret:
        name: "studio-secrets"
        key: "DATABASE_URL"
    # -- eventIngestion.environmentVariables.KAFKA_ENABLE_SSL determines whether to enable SSL for Kafka connections.
    KAFKA_ENABLE_SSL:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_CUSTOM_SSL determines whether to use custom SSL certificates for Kafka.
    KAFKA_CUSTOM_SSL:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_CA_FILE is the path to the CA certificate file for Kafka SSL.
    KAFKA_CA_FILE:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_KEY_FILE is the path to the client key file for Kafka SSL.
    KAFKA_KEY_FILE:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_CERT_FILE is the path to the client certificate file for Kafka SSL.
    KAFKA_CERT_FILE:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_REJECT_UNAUTHORIZED determines whether to verify server certificates.
    KAFKA_REJECT_UNAUTHORIZED:
      value: ""
    # -- eventIngestion.environmentVariables.NODE_TLS_REJECT_UNAUTHORIZED determines whether to allow untrusted certificates.
    NODE_TLS_REJECT_UNAUTHORIZED:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_SASL_MECHANISM is the SASL mechanism for Kafka authentication.
    # Supported values: plain, SCRAM-SHA-256, SCRAM-SHA-512
    KAFKA_SASL_MECHANISM:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_SASL_USERNAME is the SASL username for Kafka authentication.
    KAFKA_SASL_USERNAME:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_SASL_PASSWORD is the SASL password for Kafka authentication.
    KAFKA_SASL_PASSWORD:
      secret:
        name: "studio-secrets"
        key: "KAFKA_SASL_PASSWORD"
    # -- eventIngestion.environmentVariables.KAFKA_BROKER_ADDRESS is the address of the Kafka broker.
    KAFKA_BROKER_ADDRESS:
      value: ""
    # -- eventIngestion.environmentVariables.KAFKA_TOPIC is the Kafka topic for Rasa Pro assistant events.
    KAFKA_TOPIC:
      value: "rasa-events"
    # -- eventIngestion.environmentVariables.KAFKA_DLQ_TOPIC is the Kafka topic for unprocessed events.
    KAFKA_DLQ_TOPIC:
      value: "rasa-events-dlq"
    # -- eventIngestion.environmentVariables.KAFKA_GROUP_ID is the Kafka consumer group ID for Studio.
    KAFKA_GROUP_ID:
      value: "studio"

  # -- eventIngestion.envFrom defines additional environment variables from ConfigMap or Secret.
  # Example:
  # - configMapRef:
  #     name: my-configmap
  # - secretRef:
  #     name: my-secret
  envFrom:
    []

  # -- eventIngestion.additionalContainers defines additional containers to run alongside the main Event Ingestion container.
  # Example:
  # - name: sidecar
  #   image: busybox
  #   command: ["sh", "-c", "while true; do echo 'Sidecar running'; sleep 30; done"]
  additionalContainers: []

  # -- eventIngestion.volumes defines additional volumes for the Event Ingestion container.
  # Example:
  # - name: config-volume
  #   configMap:
  #     name: special-config
  volumes:
    []

  # -- eventIngestion.volumeMounts defines where to mount the volumes in the Event Ingestion container.
  # Example:
  # - name: config-volume
  #   mountPath: /etc/config
  #   readOnly: true
  volumeMounts:
    []

  # -- eventIngestion.serviceAccount defines the Kubernetes service account used by the event ingestion pod.
  serviceAccount:
    # -- eventIngestion.serviceAccount.create determines whether to create a new service account.
    create: false
    # -- eventIngestion.serviceAccount.annotations defines annotations to add to the service account.
    annotations: {}
    # -- eventIngestion.serviceAccount.name is the name of the service account to use.
    name: ""

  # -- eventIngestion.podAnnotations defines annotations to add to the event ingestion pod.
  # Example:
  #   container.apparmor.security.beta.kubernetes.io/studio-event-ingestion: runtime/default
  podAnnotations:
    {}

  # -- eventIngestion.podSecurityContext defines the security settings for the entire pod.
  podSecurityContext:
    # -- eventIngestion.podSecurityContext.enabled determines whether to enable the pod security context.
    enabled: true
    # -- eventIngestion.podSecurityContext.fsGroup is the group ID to run the container as.
    # fsGroup: 2000

  # -- eventIngestion.securityContext defines the security settings for the event ingestion container.
  securityContext:
    # -- eventIngestion.securityContext.enabled determines whether to enable the security context.
    enabled: true
    # -- eventIngestion.securityContext.allowPrivilegeEscalation determines whether to allow privilege escalation.
    allowPrivilegeEscalation: false
    # -- eventIngestion.securityContext.runAsNonRoot determines whether to run the container as a non-root user.
    runAsNonRoot: true
    # -- eventIngestion.securityContext.capabilities defines the Linux capabilities configuration.
    capabilities:
      # -- eventIngestion.securityContext.capabilities.drop defines capabilities to drop from the container.
      drop:
        - ALL
      # -- eventIngestion.securityContext.capabilities.add defines capabilities to add to the container.
      # add: ['NET_BIND_SERVICE', 'NET_RAW']
    # -- eventIngestion.securityContext.privileged determines whether to run the container in privileged mode.
    # privileged: false
    # -- eventIngestion.securityContext.readOnlyRootFilesystem determines whether to mount the root filesystem as read-only.
    # readOnlyRootFilesystem: true
    # -- eventIngestion.securityContext.runAsUser is the user ID to run the container as.
    # runAsUser: 1000
    # -- eventIngestion.securityContext.seccompProfile defines the seccomp profile configuration.
    # seccompProfile:
    #   type: RuntimeDefault

  # -- eventIngestion.resources defines the resource limits and requests for the event ingestion service.
  resources:
    {}
    # Example configuration:
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # -- eventIngestion.autoscaling defines the Horizontal Pod Autoscaling configuration.
  autoscaling:
    # -- eventIngestion.autoscaling.enabled determines whether to enable horizontal pod autoscaling.
    enabled: false
    # -- eventIngestion.autoscaling.minReplicas is the minimum number of replicas.
    minReplicas: 1
    # -- eventIngestion.autoscaling.maxReplicas is the maximum number of replicas.
    maxReplicas: 100
    # -- eventIngestion.autoscaling.targetCPUUtilizationPercentage is the target CPU utilization percentage.
    targetCPUUtilizationPercentage: 80
    # -- eventIngestion.autoscaling.targetMemoryUtilizationPercentage is the target memory utilization percentage.
    # targetMemoryUtilizationPercentage: 80

  # -- eventIngestion.nodeSelector defines which nodes the event ingestion pods can run on.
  nodeSelector: {}

  # -- eventIngestion.tolerations defines tolerations for the event ingestion pods.
  tolerations: []

  # -- eventIngestion.affinity defines affinity rules for the event ingestion pods.
  affinity: {}

# Studio Keycloak component specific configuration
keycloak:
  # -- keycloak.enabled determines whether to deploy the Keycloak authentication service.
  enabled: true
  # -- keycloak.replicaCount is the number of replicas for the Keycloak deployment.
  replicaCount: 1
  # -- keycloak.image defines the container image settings for the Keycloak service.
  image:
    # -- keycloak.image.name is the name of the Keycloak container image.
    name: "studio-keycloak"
    # -- keycloak.image.pullPolicy is the container image pull policy.
    pullPolicy: IfNotPresent

  # -- keycloak.environmentVariables defines the environment variables for the Keycloak deployment.
  # Example: Specify the string value for variables
  #   value: my-value
  # Example: Specify the value for variables sourced from a Secret.
  #   secret:
  #     name: my-secret
  #     key: my-secret-key
  # NOTE: Helm will return an error if environment variable does not have `value` or `secret` provided.
  environmentVariables:
    # -- keycloak.environmentVariables.KC_PROXY determines the proxy configuration for Keycloak.
    # Set to "edge" to enable HTTP communication between proxy/load balancer and Keycloak.
    # Useful for secure internal networks where the reverse proxy maintains HTTPS with clients.
    KC_PROXY:
      value: "edge"

  # -- keycloak.envFrom defines additional environment variables from ConfigMap or Secret.
  # Example:
  # - configMapRef:
  #     name: my-configmap
  # - secretRef:
  #     name: my-secret
  envFrom:
    []

  # -- keycloak.additionalContainers defines additional containers to run alongside the main Keycloak container.
  # Example:
  # - name: sidecar
  #   image: busybox
  #   command: ["sh", "-c", "while true; do echo 'Sidecar running'; sleep 30; done"]
  additionalContainers: []

  # -- keycloak.serviceAccount defines the Kubernetes service account used by the Keycloak pod.
  serviceAccount:
    # -- keycloak.serviceAccount.create determines whether to create a new service account.
    create: false
    # -- keycloak.serviceAccount.annotations defines annotations to add to the service account.
    annotations: {}
    # -- keycloak.serviceAccount.name is the name of the service account to use.
    name: ""

  # -- keycloak.podAnnotations defines annotations to add to the Keycloak pod.
  # Example:
  #   container.apparmor.security.beta.kubernetes.io/studio-keycloak: runtime/default
  podAnnotations:
    {}

  # -- keycloak.podSecurityContext defines the security settings for the entire pod.
  podSecurityContext:
    # -- keycloak.podSecurityContext.enabled determines whether to enable the pod security context.
    enabled: true
    # -- keycloak.podSecurityContext.fsGroup is the group ID to run the container as.
    # fsGroup: 2000

  # -- keycloak.securityContext defines the security settings for the Keycloak container.
  securityContext:
    # -- keycloak.securityContext.enabled determines whether to enable the security context.
    enabled: true
    # -- keycloak.securityContext.allowPrivilegeEscalation determines whether to allow privilege escalation.
    allowPrivilegeEscalation: false
    # -- keycloak.securityContext.runAsNonRoot determines whether to run the container as a non-root user.
    runAsNonRoot: true
    # -- keycloak.securityContext.capabilities defines the Linux capabilities configuration.
    capabilities:
      # -- keycloak.securityContext.capabilities.drop defines capabilities to drop from the container.
      drop:
        - ALL
      # -- keycloak.securityContext.capabilities.add defines capabilities to add to the container.
      # add: ['NET_BIND_SERVICE', 'NET_RAW']
    # -- keycloak.securityContext.privileged determines whether to run the container in privileged mode.
    # privileged: false
    # -- keycloak.securityContext.readOnlyRootFilesystem determines whether to mount the root filesystem as read-only.
    # readOnlyRootFilesystem: true
    # -- keycloak.securityContext.runAsUser is the user ID to run the container as.
    # runAsUser: 1000
    # -- keycloak.securityContext.seccompProfile defines the seccomp profile configuration.
    # seccompProfile:
    #   type: RuntimeDefault

  # -- keycloak.service defines how the Keycloak service is exposed within the cluster.
  service:
    # -- keycloak.service.type is the type of Kubernetes service.
    type: ClusterIP
    # -- keycloak.service.port is the port number for the service.
    port: 80
    # -- keycloak.service.targetPort is the target port in the container.
    targetPort: 8080

  # -- keycloak.livenessProbe defines the liveness probe configuration.
  livenessProbe:
    # -- keycloak.livenessProbe.enabled determines whether to enable the liveness probe.
    enabled: true
    # -- keycloak.livenessProbe.httpGet defines the HTTP GET probe configuration.
    httpGet:
      # -- keycloak.livenessProbe.httpGet.path is the path to check for liveness.
      path: /auth
      # -- keycloak.livenessProbe.httpGet.port is the port to check for liveness.
      port: 8080
      # -- keycloak.livenessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- keycloak.livenessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 30
    # -- keycloak.livenessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- keycloak.livenessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- keycloak.livenessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- keycloak.livenessProbe.failureThreshold is the number of failures before the container is considered unhealthy.
    failureThreshold: 6

  # -- keycloak.readinessProbe defines the readiness probe configuration.
  readinessProbe:
    # -- keycloak.readinessProbe.enabled determines whether to enable the readiness probe.
    enabled: true
    # -- keycloak.readinessProbe.httpGet defines the HTTP GET probe configuration.
    httpGet:
      # -- keycloak.readinessProbe.httpGet.path is the path to check for readiness.
      path: /auth
      # -- keycloak.readinessProbe.httpGet.port is the port to check for readiness.
      port: 8080
      # -- keycloak.readinessProbe.httpGet.scheme is the protocol to use for the check.
      scheme: HTTP
    # -- keycloak.readinessProbe.initialDelaySeconds is the number of seconds to wait before starting probe.
    initialDelaySeconds: 30
    # -- keycloak.readinessProbe.periodSeconds is how often to perform the probe.
    periodSeconds: 15
    # -- keycloak.readinessProbe.successThreshold is the minimum consecutive successes for the probe to be considered successful.
    successThreshold: 1
    # -- keycloak.readinessProbe.timeoutSeconds is the number of seconds after which the probe times out.
    timeoutSeconds: 5
    # -- keycloak.readinessProbe.failureThreshold is the number of failures before the container is considered not ready.
    failureThreshold: 6

  # -- keycloak.ingress defines how the Keycloak service is exposed externally.
  ingress:
    # -- keycloak.ingress.enabled determines whether to create an ingress resource.
    enabled: true
    # -- keycloak.ingress.className is the ingress class name.
    className: ""
    # -- keycloak.ingress.labels defines labels to add to the ingress resource.
    labels: {}
    # -- keycloak.ingress.additionalAnnotations defines additional annotations for the ingress resource.
    additionalAnnotations: {}
    # -- keycloak.ingress.tls defines the TLS configuration for the ingress.
    tls: []

  # -- keycloak.resources defines the resource limits and requests for the Keycloak service.
  resources:
    {}
    # Example configuration:
    # limits:
    #   cpu: 500m
    #   memory: 512Mi
    # requests:
    #   cpu: 500m
    #   memory: 512Mi

  # -- keycloak.nodeSelector defines which nodes the Keycloak pods can run on.
  nodeSelector: {}

  # -- keycloak.tolerations defines tolerations for the Keycloak pods.
  tolerations: []

  # -- keycloak.affinity defines affinity rules for the Keycloak pods.
  affinity: {}

# Network policy settings
networkPolicy:
  # -- networkPolicy.enabled specifies whether to enable network policies
  enabled: false
  # -- networkPolicy.denyAll defines whether to apply denyAll network policy
  denyAll: false
  # -- networkPolicy.nodeCIDR allows for traffic from a given CIDR - it's required in order to make kubelet able to run live and readiness probes
  nodeCIDR: []
  #  - ipBlock:
  #      cidr: 0.0.0.0/0

global:
  # -- global.additionalDeploymentLabels can be used to map organizational structures onto system objects
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  additionalDeploymentLabels: {}
  ingressHost:

# -- Controls whether the pod may use the node network namespace
hostNetwork: false

# -- dnsPolicy specifies Pod's DNS policy
## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
dnsPolicy: ""

# -- dnsConfig specifies Pod's DNS condig
## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config
dnsConfig:
  {}
  # options:
  # - name: ndots
  #   value: "1"

# -- deploymentAnnotations defines annotations to add to all Studio deployments
deploymentAnnotations:
  {}
  #  key: "value"

# -- deploymentLabels defines labels to add to all Studio deployment
deploymentLabels: {}

# -- podLabels defines labels to add to all Studio pod(s)
podLabels: {}

replicated:
  enabled: false
  sdkVersion: "1.5.2"

# -- Define the resources for the Rasa Pro model server
rasa:
  enabled: true
  fullnameOverride: rasapro

  rasa:
    replicaCount: 1
    image:
      repository: europe-west3-docker.pkg.dev/rasa-releases/rasa-pro/rasa-pro
      tag: "3.12.6-latest"

    strategy:
      type: Recreate

    settings:
      useDefaultArgs: false
      mountDefaultConfigmap: false

    command: ["python", "-m", "rasa.model_service"]

    overrideEnv:
      - name: "RASA_PRO_LICENSE"
        valueFrom:
          secretKeyRef:
            name: "studio-secrets"
            key: "RASA_PRO_LICENSE_SECRET_KEY"
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            name: "studio-secrets"
            key: "OPENAI_API_KEY_SECRET_KEY"

    envFrom:
      - configMapRef:
          name: shared-environment

    service:
      port: 80
      targetPort: 8000

    livenessProbe:
      enabled: true
      httpGet:
        path: /
        port: 8000
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 15
      successThreshold: 1
      timeoutSeconds: 5
      failureThreshold: 6

    readinessProbe:
      enabled: true
      httpGet:
        path: /
        port: 8000
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 15
      successThreshold: 1
      timeoutSeconds: 5
      failureThreshold: 6

    ingress:
      enabled: true
      annotations: {}
      hosts:
        # -- Please update the below URL with the correct host name of the Studio deployment
        - host: *dns_hostname
          paths:
            - path: /talk
              pathType: Prefix

    persistence:
      create: true
      storageCapacity: 1Gi
      storageRequests: 1Gi
      # -- Make sure to set the correct storage class name based on your cluster configuration
      storageClassName:
      hostPath:
        enabled: false

    podSecurityContext:
      # -- User ID of the container to access the mounted volume
      fsGroup: 1001

    # -- rasa.resources specifies the resources limits and requests
    resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  rasaProServices:
    enabled: false
